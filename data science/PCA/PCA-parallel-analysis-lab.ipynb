{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and Horn's Parallel Analysis Lab\n",
    "\n",
    "In this lab you'll practice using PCA on two datasets: heptathalon performance \n",
    "Horn's Parallel Analysis is a way to determine how many components you should keep after using a PCA on your data. Essentially it will tell you which of your components are likely noise which can be discarded.\n",
    "\n",
    "---\n",
    "\n",
    "### Load packages and heptathalon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hep = pd.read_csv('heptathlon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'hurdles', u'highjump', u'shot', u'run200m', u'longjump', u'javelin',\n",
       "       u'run800m', u'score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hep.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep.columns = ['athlete'] + hep.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>athlete</th>\n",
       "      <th>hurdles</th>\n",
       "      <th>highjump</th>\n",
       "      <th>shot</th>\n",
       "      <th>run200m</th>\n",
       "      <th>longjump</th>\n",
       "      <th>javelin</th>\n",
       "      <th>run800m</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joyner-Kersee (USA)</td>\n",
       "      <td>12.69</td>\n",
       "      <td>1.86</td>\n",
       "      <td>15.80</td>\n",
       "      <td>22.56</td>\n",
       "      <td>7.27</td>\n",
       "      <td>45.66</td>\n",
       "      <td>128.51</td>\n",
       "      <td>7291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John (GDR)</td>\n",
       "      <td>12.85</td>\n",
       "      <td>1.80</td>\n",
       "      <td>16.23</td>\n",
       "      <td>23.65</td>\n",
       "      <td>6.71</td>\n",
       "      <td>42.56</td>\n",
       "      <td>126.12</td>\n",
       "      <td>6897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Behmer (GDR)</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.83</td>\n",
       "      <td>14.20</td>\n",
       "      <td>23.10</td>\n",
       "      <td>6.68</td>\n",
       "      <td>44.54</td>\n",
       "      <td>124.20</td>\n",
       "      <td>6858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               athlete  hurdles  highjump   shot  run200m  longjump  javelin  \\\n",
       "0  Joyner-Kersee (USA)    12.69      1.86  15.80    22.56      7.27    45.66   \n",
       "1           John (GDR)    12.85      1.80  16.23    23.65      6.71    42.56   \n",
       "2         Behmer (GDR)    13.20      1.83  14.20    23.10      6.68    44.54   \n",
       "\n",
       "   run800m  score  \n",
       "0   128.51   7291  \n",
       "1   126.12   6897  \n",
       "2   124.20   6858  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hep.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hurdles</th>\n",
       "      <th>highjump</th>\n",
       "      <th>shot</th>\n",
       "      <th>run200m</th>\n",
       "      <th>longjump</th>\n",
       "      <th>javelin</th>\n",
       "      <th>run800m</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hurdles</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.811403</td>\n",
       "      <td>-0.651335</td>\n",
       "      <td>0.773721</td>\n",
       "      <td>-0.912134</td>\n",
       "      <td>-0.007763</td>\n",
       "      <td>0.779257</td>\n",
       "      <td>-0.923198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highjump</th>\n",
       "      <td>-0.811403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440786</td>\n",
       "      <td>-0.487664</td>\n",
       "      <td>0.782442</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>-0.591163</td>\n",
       "      <td>0.767359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shot</th>\n",
       "      <td>-0.651335</td>\n",
       "      <td>0.440786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.682670</td>\n",
       "      <td>0.743073</td>\n",
       "      <td>0.268989</td>\n",
       "      <td>-0.419620</td>\n",
       "      <td>0.799699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run200m</th>\n",
       "      <td>0.773721</td>\n",
       "      <td>-0.487664</td>\n",
       "      <td>-0.682670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.817205</td>\n",
       "      <td>-0.333043</td>\n",
       "      <td>0.616810</td>\n",
       "      <td>-0.864883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longjump</th>\n",
       "      <td>-0.912134</td>\n",
       "      <td>0.782442</td>\n",
       "      <td>0.743073</td>\n",
       "      <td>-0.817205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067108</td>\n",
       "      <td>-0.699511</td>\n",
       "      <td>0.950437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>javelin</th>\n",
       "      <td>-0.007763</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.268989</td>\n",
       "      <td>-0.333043</td>\n",
       "      <td>0.067108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020049</td>\n",
       "      <td>0.253147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run800m</th>\n",
       "      <td>0.779257</td>\n",
       "      <td>-0.591163</td>\n",
       "      <td>-0.419620</td>\n",
       "      <td>0.616810</td>\n",
       "      <td>-0.699511</td>\n",
       "      <td>0.020049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.772776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>-0.923198</td>\n",
       "      <td>0.767359</td>\n",
       "      <td>0.799699</td>\n",
       "      <td>-0.864883</td>\n",
       "      <td>0.950437</td>\n",
       "      <td>0.253147</td>\n",
       "      <td>-0.772776</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hurdles  highjump      shot   run200m  longjump   javelin  \\\n",
       "hurdles   1.000000 -0.811403 -0.651335  0.773721 -0.912134 -0.007763   \n",
       "highjump -0.811403  1.000000  0.440786 -0.487664  0.782442  0.002153   \n",
       "shot     -0.651335  0.440786  1.000000 -0.682670  0.743073  0.268989   \n",
       "run200m   0.773721 -0.487664 -0.682670  1.000000 -0.817205 -0.333043   \n",
       "longjump -0.912134  0.782442  0.743073 -0.817205  1.000000  0.067108   \n",
       "javelin  -0.007763  0.002153  0.268989 -0.333043  0.067108  1.000000   \n",
       "run800m   0.779257 -0.591163 -0.419620  0.616810 -0.699511  0.020049   \n",
       "score    -0.923198  0.767359  0.799699 -0.864883  0.950437  0.253147   \n",
       "\n",
       "           run800m     score  \n",
       "hurdles   0.779257 -0.923198  \n",
       "highjump -0.591163  0.767359  \n",
       "shot     -0.419620  0.799699  \n",
       "run200m   0.616810 -0.864883  \n",
       "longjump -0.699511  0.950437  \n",
       "javelin   0.020049  0.253147  \n",
       "run800m   1.000000 -0.772776  \n",
       "score    -0.772776  1.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hep.iloc[:,1:].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "hep_n = StandardScaler().fit_transform(hep.iloc[:,1:-1])\n",
    "hep_n[:,[0,3,6]] *= -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA().fit(hep_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.45287105, -0.37719923, -0.3630725 , -0.40789504, -0.45623185,\n",
       "        -0.075409  , -0.37495938],\n",
       "       [-0.15792058, -0.24807386,  0.28940743,  0.26038545, -0.05587394,\n",
       "         0.84169212, -0.22448984],\n",
       "       [ 0.04514996,  0.36777902, -0.67618919, -0.08359211, -0.13931653,\n",
       "         0.47156016,  0.39585671],\n",
       "       [ 0.02653873,  0.67999172,  0.12431725, -0.3610658 ,  0.11129249,\n",
       "         0.12079924, -0.6034113 ],\n",
       "       [ 0.09494792, -0.01879888, -0.51165201,  0.64983404,  0.1842981 ,\n",
       "        -0.13510669, -0.50432116],\n",
       "       [ 0.78334101, -0.09939981,  0.05085983, -0.02495639, -0.59020972,\n",
       "         0.02724076, -0.1555552 ],\n",
       "       [ 0.38024707, -0.43393114, -0.21762491, -0.45338483,  0.61206388,\n",
       "         0.17294667, -0.09830963]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hurdles -0.452871046493\n",
      "highjump -0.377199230356\n",
      "shot -0.363072497179\n",
      "run200m -0.407895041255\n",
      "longjump -0.456231849776\n",
      "javelin -0.0754089953116\n",
      "run800m -0.374959378673\n"
     ]
    }
   ],
   "source": [
    "pca1_evec = pca.components_[0]\n",
    "for weight, event in zip(pca1_evec, hep.iloc[:,1:-1].columns):\n",
    "    print event, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hurdles 0.0451499646706\n",
      "highjump 0.367779024656\n",
      "shot -0.676189188799\n",
      "run200m -0.0835921094786\n",
      "longjump -0.139316525161\n",
      "javelin 0.471560156559\n",
      "run800m 0.395856709505\n"
     ]
    }
   ],
   "source": [
    "pca2_evec = pca.components_[2]\n",
    "for weight, event in zip(pca2_evec, hep.iloc[:,1:-1].columns):\n",
    "    print event, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create dataframe excluding athlete and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hurdles</th>\n",
       "      <th>highjump</th>\n",
       "      <th>shot</th>\n",
       "      <th>run200m</th>\n",
       "      <th>longjump</th>\n",
       "      <th>javelin</th>\n",
       "      <th>run800m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.69</td>\n",
       "      <td>1.86</td>\n",
       "      <td>15.80</td>\n",
       "      <td>22.56</td>\n",
       "      <td>7.27</td>\n",
       "      <td>45.66</td>\n",
       "      <td>128.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.85</td>\n",
       "      <td>1.80</td>\n",
       "      <td>16.23</td>\n",
       "      <td>23.65</td>\n",
       "      <td>6.71</td>\n",
       "      <td>42.56</td>\n",
       "      <td>126.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.83</td>\n",
       "      <td>14.20</td>\n",
       "      <td>23.10</td>\n",
       "      <td>6.68</td>\n",
       "      <td>44.54</td>\n",
       "      <td>124.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.61</td>\n",
       "      <td>1.80</td>\n",
       "      <td>15.23</td>\n",
       "      <td>23.92</td>\n",
       "      <td>6.25</td>\n",
       "      <td>42.78</td>\n",
       "      <td>132.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.51</td>\n",
       "      <td>1.74</td>\n",
       "      <td>14.76</td>\n",
       "      <td>23.93</td>\n",
       "      <td>6.32</td>\n",
       "      <td>47.46</td>\n",
       "      <td>127.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.75</td>\n",
       "      <td>1.83</td>\n",
       "      <td>13.50</td>\n",
       "      <td>24.65</td>\n",
       "      <td>6.33</td>\n",
       "      <td>42.82</td>\n",
       "      <td>125.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.38</td>\n",
       "      <td>1.80</td>\n",
       "      <td>12.88</td>\n",
       "      <td>23.59</td>\n",
       "      <td>6.37</td>\n",
       "      <td>40.28</td>\n",
       "      <td>132.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.55</td>\n",
       "      <td>1.80</td>\n",
       "      <td>14.13</td>\n",
       "      <td>24.48</td>\n",
       "      <td>6.47</td>\n",
       "      <td>38.00</td>\n",
       "      <td>133.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.63</td>\n",
       "      <td>1.83</td>\n",
       "      <td>14.28</td>\n",
       "      <td>24.86</td>\n",
       "      <td>6.11</td>\n",
       "      <td>42.20</td>\n",
       "      <td>136.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.25</td>\n",
       "      <td>1.77</td>\n",
       "      <td>12.62</td>\n",
       "      <td>23.59</td>\n",
       "      <td>6.28</td>\n",
       "      <td>39.06</td>\n",
       "      <td>134.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.75</td>\n",
       "      <td>1.86</td>\n",
       "      <td>13.01</td>\n",
       "      <td>25.03</td>\n",
       "      <td>6.34</td>\n",
       "      <td>37.86</td>\n",
       "      <td>131.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.24</td>\n",
       "      <td>1.80</td>\n",
       "      <td>12.88</td>\n",
       "      <td>23.59</td>\n",
       "      <td>6.37</td>\n",
       "      <td>40.28</td>\n",
       "      <td>132.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.85</td>\n",
       "      <td>1.86</td>\n",
       "      <td>11.58</td>\n",
       "      <td>24.87</td>\n",
       "      <td>6.05</td>\n",
       "      <td>47.50</td>\n",
       "      <td>134.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.71</td>\n",
       "      <td>1.83</td>\n",
       "      <td>13.16</td>\n",
       "      <td>24.78</td>\n",
       "      <td>6.12</td>\n",
       "      <td>44.58</td>\n",
       "      <td>142.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.79</td>\n",
       "      <td>1.80</td>\n",
       "      <td>12.32</td>\n",
       "      <td>24.61</td>\n",
       "      <td>6.08</td>\n",
       "      <td>45.44</td>\n",
       "      <td>137.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.93</td>\n",
       "      <td>1.86</td>\n",
       "      <td>14.21</td>\n",
       "      <td>25.00</td>\n",
       "      <td>6.40</td>\n",
       "      <td>38.60</td>\n",
       "      <td>146.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.47</td>\n",
       "      <td>1.80</td>\n",
       "      <td>12.75</td>\n",
       "      <td>25.47</td>\n",
       "      <td>6.34</td>\n",
       "      <td>35.76</td>\n",
       "      <td>138.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.07</td>\n",
       "      <td>1.83</td>\n",
       "      <td>12.69</td>\n",
       "      <td>24.83</td>\n",
       "      <td>6.13</td>\n",
       "      <td>44.34</td>\n",
       "      <td>146.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.39</td>\n",
       "      <td>1.71</td>\n",
       "      <td>12.68</td>\n",
       "      <td>24.92</td>\n",
       "      <td>6.10</td>\n",
       "      <td>37.76</td>\n",
       "      <td>138.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14.04</td>\n",
       "      <td>1.77</td>\n",
       "      <td>11.81</td>\n",
       "      <td>25.61</td>\n",
       "      <td>5.99</td>\n",
       "      <td>35.68</td>\n",
       "      <td>133.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.31</td>\n",
       "      <td>1.77</td>\n",
       "      <td>11.66</td>\n",
       "      <td>25.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>39.48</td>\n",
       "      <td>133.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>12.95</td>\n",
       "      <td>25.50</td>\n",
       "      <td>5.50</td>\n",
       "      <td>39.64</td>\n",
       "      <td>144.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14.85</td>\n",
       "      <td>1.68</td>\n",
       "      <td>10.00</td>\n",
       "      <td>25.23</td>\n",
       "      <td>5.47</td>\n",
       "      <td>39.14</td>\n",
       "      <td>137.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.53</td>\n",
       "      <td>1.71</td>\n",
       "      <td>10.83</td>\n",
       "      <td>26.61</td>\n",
       "      <td>5.50</td>\n",
       "      <td>39.26</td>\n",
       "      <td>139.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.42</td>\n",
       "      <td>1.50</td>\n",
       "      <td>11.78</td>\n",
       "      <td>26.16</td>\n",
       "      <td>4.88</td>\n",
       "      <td>46.38</td>\n",
       "      <td>163.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hurdles  highjump   shot  run200m  longjump  javelin  run800m\n",
       "0     12.69      1.86  15.80    22.56      7.27    45.66   128.51\n",
       "1     12.85      1.80  16.23    23.65      6.71    42.56   126.12\n",
       "2     13.20      1.83  14.20    23.10      6.68    44.54   124.20\n",
       "3     13.61      1.80  15.23    23.92      6.25    42.78   132.24\n",
       "4     13.51      1.74  14.76    23.93      6.32    47.46   127.90\n",
       "5     13.75      1.83  13.50    24.65      6.33    42.82   125.79\n",
       "6     13.38      1.80  12.88    23.59      6.37    40.28   132.54\n",
       "7     13.55      1.80  14.13    24.48      6.47    38.00   133.65\n",
       "8     13.63      1.83  14.28    24.86      6.11    42.20   136.05\n",
       "9     13.25      1.77  12.62    23.59      6.28    39.06   134.74\n",
       "10    13.75      1.86  13.01    25.03      6.34    37.86   131.49\n",
       "11    13.24      1.80  12.88    23.59      6.37    40.28   132.54\n",
       "12    13.85      1.86  11.58    24.87      6.05    47.50   134.93\n",
       "13    13.71      1.83  13.16    24.78      6.12    44.58   142.82\n",
       "14    13.79      1.80  12.32    24.61      6.08    45.44   137.06\n",
       "15    13.93      1.86  14.21    25.00      6.40    38.60   146.67\n",
       "16    13.47      1.80  12.75    25.47      6.34    35.76   138.48\n",
       "17    14.07      1.83  12.69    24.83      6.13    44.34   146.43\n",
       "18    14.39      1.71  12.68    24.92      6.10    37.76   138.02\n",
       "19    14.04      1.77  11.81    25.61      5.99    35.68   133.90\n",
       "20    14.31      1.77  11.66    25.69      5.75    39.48   133.35\n",
       "21    14.23      1.71  12.95    25.50      5.50    39.64   144.02\n",
       "22    14.85      1.68  10.00    25.23      5.47    39.14   137.30\n",
       "23    14.53      1.71  10.83    26.61      5.50    39.26   139.17\n",
       "24    16.42      1.50  11.78    26.16      4.88    46.38   163.43"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = hep.drop(['athlete','score'],axis=1)\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Examine the correlation between the different events\n",
    "\n",
    "Plot a heatmap if you want to get fancy. What does the correlation matrix tell you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hurdles</th>\n",
       "      <th>highjump</th>\n",
       "      <th>shot</th>\n",
       "      <th>run200m</th>\n",
       "      <th>longjump</th>\n",
       "      <th>javelin</th>\n",
       "      <th>run800m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hurdles</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.811403</td>\n",
       "      <td>-0.651335</td>\n",
       "      <td>0.773721</td>\n",
       "      <td>-0.912134</td>\n",
       "      <td>-0.007763</td>\n",
       "      <td>0.779257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highjump</th>\n",
       "      <td>-0.811403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.440786</td>\n",
       "      <td>-0.487664</td>\n",
       "      <td>0.782442</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>-0.591163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shot</th>\n",
       "      <td>-0.651335</td>\n",
       "      <td>0.440786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.682670</td>\n",
       "      <td>0.743073</td>\n",
       "      <td>0.268989</td>\n",
       "      <td>-0.419620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run200m</th>\n",
       "      <td>0.773721</td>\n",
       "      <td>-0.487664</td>\n",
       "      <td>-0.682670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.817205</td>\n",
       "      <td>-0.333043</td>\n",
       "      <td>0.616810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longjump</th>\n",
       "      <td>-0.912134</td>\n",
       "      <td>0.782442</td>\n",
       "      <td>0.743073</td>\n",
       "      <td>-0.817205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067108</td>\n",
       "      <td>-0.699511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>javelin</th>\n",
       "      <td>-0.007763</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.268989</td>\n",
       "      <td>-0.333043</td>\n",
       "      <td>0.067108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run800m</th>\n",
       "      <td>0.779257</td>\n",
       "      <td>-0.591163</td>\n",
       "      <td>-0.419620</td>\n",
       "      <td>0.616810</td>\n",
       "      <td>-0.699511</td>\n",
       "      <td>0.020049</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hurdles  highjump      shot   run200m  longjump   javelin   run800m\n",
       "hurdles   1.000000 -0.811403 -0.651335  0.773721 -0.912134 -0.007763  0.779257\n",
       "highjump -0.811403  1.000000  0.440786 -0.487664  0.782442  0.002153 -0.591163\n",
       "shot     -0.651335  0.440786  1.000000 -0.682670  0.743073  0.268989 -0.419620\n",
       "run200m   0.773721 -0.487664 -0.682670  1.000000 -0.817205 -0.333043  0.616810\n",
       "longjump -0.912134  0.782442  0.743073 -0.817205  1.000000  0.067108 -0.699511\n",
       "javelin  -0.007763  0.002153  0.268989 -0.333043  0.067108  1.000000  0.020049\n",
       "run800m   0.779257 -0.591163 -0.419620  0.616810 -0.699511  0.020049  1.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Fit a PCA on the standardized data using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hep_pca = PCA()\n",
    "hep_pca.fit(dt)\n",
    "stats_pcs = hep_pca.transform(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create a DataFrame with the principal components\n",
    "\n",
    "Add back in the athelete and score columns from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats_pcs = pd.DataFrame(stats_pcs, columns=['PC'+str(i) for i in range(1,8)])\n",
    "stats_pcs['PCA1'] = hep.iloc[:,0]\n",
    "stats_pcs['PCA2'] = hep.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.95086924e-02,  -5.56978060e-03,  -7.79060896e-02,\n",
       "          7.29675448e-02,  -4.03692989e-02,   6.68558370e-03,\n",
       "          9.90994208e-01],\n",
       "       [ -9.48914170e-03,   5.64714749e-04,   1.35928233e-01,\n",
       "         -1.01200427e-01,   1.48845034e-02,   9.85295451e-01,\n",
       "          1.27652701e-02],\n",
       "       [  2.21808290e-01,  -1.45140493e-02,  -8.83740455e-01,\n",
       "          3.10057000e-01,  -1.84943194e-01,   1.60212685e-01,\n",
       "         -1.16558146e-01],\n",
       "       [ -3.27376739e-01,   2.12385605e-02,  -4.25006542e-01,\n",
       "         -8.15852202e-01,   2.04198278e-01,  -3.21690666e-02,\n",
       "          5.82772002e-02],\n",
       "       [  8.07029319e-01,  -1.40138230e-01,   1.04422071e-01,\n",
       "         -4.61786801e-01,  -3.18993151e-01,  -4.88038779e-02,\n",
       "         -2.78475644e-02],\n",
       "       [ -4.24850883e-01,  -9.83735676e-02,   5.17448016e-02,\n",
       "         -8.24862444e-02,  -8.94592570e-01,  -6.17043752e-03,\n",
       "          2.98704278e-03],\n",
       "       [ -8.31231453e-02,  -9.84881131e-01,  -1.56496439e-02,\n",
       "          5.13129737e-02,   1.42110352e-01,   5.03300452e-03,\n",
       "          1.04145084e-03]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hep_pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plot the variance explained (ratio) of your components\n",
    "\n",
    "Explain what this chart tells you about your components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.71685631e+01,   1.23792986e+01,   1.84335142e+00,\n",
       "         3.29337449e-01,   1.00663041e-01,   2.07791268e-02,\n",
       "         1.06131446e-03])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hep_pca.explained_variance_ #............????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-6467f5066110>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats_pcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhep_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats_pcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhep_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'explained variance of components'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'principal component'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zyousefi.ORADEV\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\matplotlib\\__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1810\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1811\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1812\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1813\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1814\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zyousefi.ORADEV\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\matplotlib\\axes\\_axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1422\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'color'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1425\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1426\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zyousefi.ORADEV\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\matplotlib\\axes\\_base.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zyousefi.ORADEV\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\matplotlib\\axes\\_base.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\zyousefi.ORADEV\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\matplotlib\\axes\\_base.pyc\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must have same first dimension\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y can be no greater than 2-D\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABD4AAALkCAYAAADnIvWmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd361dd8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 370,
       "width": 543
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(range(1, stats_pcs.shape[1]+1), hep_pca.explained_variance_ratio_, lw=2)\n",
    "ax.scatter(range(1, stats_pcs.shape[1]+1), hep_pca.explained_variance_ratio_, s=100)\n",
    "ax.set_title('explained variance of components')\n",
    "ax.set_xlabel('principal component')\n",
    "ax.set_ylabel('explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Print out the weights/eigenvectors (.components_ ) with their corresponding variables for PC1 and PC2\n",
    "\n",
    "Based on how the original variables are weighted to calculate the components, how would you describe PC1 and PC2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PC1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-306b4e764c13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats_pcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhep_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPC1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PC1' is not defined"
     ]
    }
   ],
   "source": [
    "for col, comp in zip(stats_pcs.columns, hep_pca.components_[PC1]):\n",
    "    print col, comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-ba7d201a9fae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhep_pca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPCA2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "for col, comp in zip(stats.columns, hep_pca.components_[PCA2]):\n",
    "    print col, comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.935036</td>\n",
       "      <td>4.623502</td>\n",
       "      <td>-1.932601</td>\n",
       "      <td>0.596760</td>\n",
       "      <td>-0.044456</td>\n",
       "      <td>-0.256073</td>\n",
       "      <td>0.041581</td>\n",
       "      <td>Joyner-Kersee (USA)</td>\n",
       "      <td>7291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.244140</td>\n",
       "      <td>1.476831</td>\n",
       "      <td>-2.052805</td>\n",
       "      <td>-0.682836</td>\n",
       "      <td>0.031115</td>\n",
       "      <td>0.127155</td>\n",
       "      <td>0.038903</td>\n",
       "      <td>John (GDR)</td>\n",
       "      <td>6897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.990222</td>\n",
       "      <td>3.179182</td>\n",
       "      <td>0.194416</td>\n",
       "      <td>0.332989</td>\n",
       "      <td>0.317783</td>\n",
       "      <td>-0.075283</td>\n",
       "      <td>-0.012488</td>\n",
       "      <td>Behmer (GDR)</td>\n",
       "      <td>6858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.008781</td>\n",
       "      <td>1.594408</td>\n",
       "      <td>-1.509790</td>\n",
       "      <td>-0.471268</td>\n",
       "      <td>0.380926</td>\n",
       "      <td>0.158688</td>\n",
       "      <td>-0.052657</td>\n",
       "      <td>Sablovskaite (URS)</td>\n",
       "      <td>6540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.250504</td>\n",
       "      <td>6.087248</td>\n",
       "      <td>0.130071</td>\n",
       "      <td>-0.637390</td>\n",
       "      <td>0.125062</td>\n",
       "      <td>0.077468</td>\n",
       "      <td>0.051599</td>\n",
       "      <td>Choubenkova (URS)</td>\n",
       "      <td>6540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  -7.935036  4.623502 -1.932601  0.596760 -0.044456 -0.256073  0.041581   \n",
       "1 -10.244140  1.476831 -2.052805 -0.682836  0.031115  0.127155  0.038903   \n",
       "2 -11.990222  3.179182  0.194416  0.332989  0.317783 -0.075283 -0.012488   \n",
       "3  -4.008781  1.594408 -1.509790 -0.471268  0.380926  0.158688 -0.052657   \n",
       "4  -8.250504  6.087248  0.130071 -0.637390  0.125062  0.077468  0.051599   \n",
       "\n",
       "                  PCA1  PCA2  \n",
       "0  Joyner-Kersee (USA)  7291  \n",
       "1           John (GDR)  6897  \n",
       "2         Behmer (GDR)  6858  \n",
       "3   Sablovskaite (URS)  6540  \n",
       "4    Choubenkova (URS)  6540  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_pcs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plot PC1 vs. PC2. Which athletes are notable on each component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.scatter(stats_pcs.PC1.values, stats_pcs.PC2.values, s=0)\n",
    "\n",
    "for i, txt in enumerate(stats_pcs.athlete.values):\n",
    "    ax.annotate(txt, (0, 0), (stats_pcs.PC1.values[i], stats_pcs.PC2.values[i]),\n",
    "            arrowprops=dict(arrowstyle='<-', color='black', linewidth=1.5),\n",
    "            xycoords='data', textcoords='data', fontsize=12, color=\"black\")\n",
    "\n",
    "ax.set_title('PC1 (run) vs. PC2 (javelin/shot)')\n",
    "ax.set_xlabel('principal component 1 (run)')\n",
    "ax.set_ylabel('principal component 2 (javelin/shot)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plot PC1 vs. score and PC2 vs. score. What does this tell you about the relationship between the events and the score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "ax.scatter(stats_pcs.???.????, stats_pcs.???.??, s=100)\n",
    "\n",
    "ax.set_title('PC1 (run) vs. score')\n",
    "ax.set_xlabel('principal component 1 (run)')\n",
    "ax.set_ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "ax.scatter(??, ???, s=100, c='darkred')\n",
    "\n",
    "ax.set_title('PC2 (shot/javelin) vs. score')\n",
    "ax.set_xlabel('principal component 2 (shot/javelin)')\n",
    "ax.set_ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Horn's parallel analysis\n",
    "\n",
    "You can determine the appropriate number of components to keep by using a bootstrapping procedure known as Horn's Parallel Analysis. This is (as far as I know) the gold standard in determining which components aren't noise.\n",
    "\n",
    "How to do the parallel analysis (pseudocode):\n",
    "\n",
    "    for n iterations:\n",
    "        create normally distributed random data the same shape as your data\n",
    "        fit a PCA on the random data\n",
    "        pull out the eigenvalues\n",
    "    select a percentile of the eigenvalues as your threshold (0.5 = median, 0.95 = 95% confidence, etc.)\n",
    "    plot the random component eigenvalues at that percentile against your data's pca eigenvalues\n",
    "    components above the selected percentile are not noise, those under are\n",
    "    \n",
    "    \n",
    "Write a function to perform the parallel analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def horn_parallel_analysis(shape, iters=1000, percentile=95):\n",
    "    pca = PCA(n_components=shape[1])\n",
    "    eigenvals = []\n",
    "    for i in range(iters):\n",
    "        rdata = np.random.normal(0,1,size=shape)\n",
    "        pca.fit(rdata)\n",
    "        eigenvals.append(pca.explained_variance_)\n",
    "    eigenvals = np.array(eigenvals)\n",
    "    return np.percentile(eigenvals, percentile, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Run parallel analysis for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hep_pa = horn_parallel_analysis(hep.iloc[:,1:-1].shape, percentile=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plot the wine eigenvalues (`.variance_explained_`) against the parallel analysis random eigenvalue cutoffs\n",
    "\n",
    "How many components are not noise, based on the chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(range(1, hep.iloc[:,1:-1].shape[1]+1), hep_pca.explained_variance_, lw=2)\n",
    "ax.scatter(range(1, hep.iloc[:,1:-1].shape[1]+1), hep_pca.explained_variance_, s=50)\n",
    "\n",
    "ax.plot(range(1, len(hep_pa)+1), hep_pa, lw=2, color='darkred')\n",
    "ax.scatter(range(1, len(hep_pa)+1), hep_pa, s=40, color='darkred')\n",
    "\n",
    "\n",
    "ax.set_title('Horns parallel analysis on hep data components')\n",
    "ax.set_xlabel('principal component')\n",
    "ax.set_ylabel('eigenvalue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
