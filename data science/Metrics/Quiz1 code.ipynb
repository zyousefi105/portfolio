{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree has accuracy:  0.654237288136\n",
      "GaussianNB has accuracy:  0.694915254237\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# In this and the following exercises, you'll be adding train test splits to the data\n",
    "# to see how it changes the performance of each classifier\n",
    "#\n",
    "# The code provided will load the Titanic dataset, then train\n",
    "# a decision tree (the method you used in your project) and a Bayesian classifier (as\n",
    "# discussed in the introduction videos). You don't need to worry about how these work for\n",
    "# now. \n",
    "#\n",
    "# What you do need to do is import a train/test split, train the classifiers on the\n",
    "# training data, and store the resulting accuracy scores in the dictionary provided.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split #sklearn.cross_validation for older versions\n",
    "\n",
    "# Load the dataset\n",
    "X = pd.read_csv('titanic_data.csv')\n",
    "# Limit to numeric data\n",
    "X = X._get_numeric_data()\n",
    "# Separate the labels\n",
    "y = X['Survived']\n",
    "# Remove labels from the inputs, and age due to missing data\n",
    "del X['Age'], X['Survived']\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# TODO: split the data into training and testing sets,\n",
    "# using the standard settings for train_test_split.\n",
    "# Then, train and test the classifiers with your newly split data instead of X and y.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) \n",
    "#42 can be any value just to have the same set of sets\n",
    "\n",
    "# The decision tree classifier\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf1.fit(X_train,y_train)\n",
    "print \"Decision Tree has accuracy: \",accuracy_score(clf1.predict(X_test),y_test) \n",
    "# so fit and test shouldn't be done on X,Y the whole dataset but the train and\n",
    "#test data set then we can correctly compare two models\n",
    "# The naive Bayes classifier\n",
    "\n",
    "clf2 = GaussianNB()\n",
    "clf2.fit(X_train,y_train)\n",
    "print \"GaussianNB has accuracy: \",accuracy_score(clf2.predict(X_test),y_test) #clf2.predict(X_test),y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
